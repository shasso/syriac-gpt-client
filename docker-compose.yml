
services:
  api:
    build:
      context: ../syriac-gpt-api
      dockerfile: Dockerfile
    image: syriac-gpt-api:latest
    container_name: assyrian-api
    ports:
      - "8000:8000"
    volumes:
      - ../syriac-gpt-api/models:/app/models:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
      # Model selection parameters (see main.py manifest loader)
      # Set MODEL_ID to choose which entry in manifest.json to load at startup.
      # Ensure manifest.json exists under ./models (mounted read-only) or adjust path.
      - MODEL_ID=Makaru-SPM8K-Scribes-4M
      - MODEL_MANIFEST_PATH=/app/models/manifest.json
    gpus: all
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - assyrian-net

  client:
    build:
      context: .
      dockerfile: Dockerfile
    image: modern-assyrian-client:latest
    container_name: assyrian-client
    ports:
      - "8080:80"
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost/"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - assyrian-net

networks:
  assyrian-net:
    driver: bridge
